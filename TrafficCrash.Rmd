---
title: "Road accident cause analysis and accident severity prediction with Machine Learning"
subtitle: WQD7004 Programming for Data Science Group Project - Group 14
author: "Mithirendra Maniam, Yao Hong, Tan Wei Ven, Nur Ain Sufi Baharozaman"
date: "2023-11-02"
output: html_document
---
---

## 1. PROJECT INTRODUCTION

```{r, echo=FALSE, out.width="50%"}
# Define variable containing url
url <- "https://res.cloudinary.com/dmeglmbmj/image/upload/v1699100625/Traffic_Crash_d1p0rh.jpg"
```

<center><img src="`r url`" width="500" /></center>  

Road accidents are a major concern all over the world, since they cause casualties, injuries, and fatalities each year. Accidents also cause significant economic losses. The 2018 report of the World Health Organization states that more than 1.35 million people die each year from causes related to road accidents. An additional 20-50 million are injured or disabled [1]. If factors that cause accidents can be better understood and predicted, it might be possible to take measures to mitigate the damages and its severity [2].

---

## 2. PROJECT RESEARCH QUESTIONS
Many factors are responsible for causing road accidents. How to reduce the occurrence of fatal traffic accidents and improve road safety has been a significant problem for both governments and research institutions. Knowing what the influential factors are and how they affect the accidents can help better understand the cause-effect behind. This is beneficial to improve the estimation of the accident severity and preparation of countermeasures.[3]

The purpose of this project is to predict road accident hotspots and analyse non-human factors causing accidents, using traffic crash data from 2011 to 2023 from the New Zealand governments open data portal (data.gov.nz). Here are research questions that the project is aiming to answer:

1. What are the major accident areas and vehicle types in New Zealand?
2. Are there any non-human factors that cause more severe accidents? 
3. Can the data predict future severity of road accidents based on past data?  

---

## 3. PROJECT RESEARCH OBJECTIVES
The research objectives for the project are:

1. Identify major accident areas and vehicle types involved.
2. Identify non-human variables that may cause and increase the likelihood of severe accidents, including high fatalities.
3. Develop machine learning models to predict future road accident severity.  

---

## 4. LITERATURE REVIEW
Given the significant impact to society and mortality rates, accident prediction has been extensively studied with many different models. From a methodology perspective, there are many that have been explored. In 2019, Herbert et. al. [4] used a balanced random forest algorithm to study the accidents that occurred in Montreal. Overall, the algorithms predicted 85 percent of Montreal incidents, with a false positive rate (FPR) of 13%. Another study in 2019 on a GIS-based data mining methodology framework to analyze the influential factors of fatal traffic accidents showed that XGBoost obtained the highest modeling accuracy. [3] Fiorentini in 2020 gave outcomes from a random undersampling majority-class (RUMC) based models provide an enhancement in the reliability of the classifiers for detecting fatal crashes and those causing injury. Indeed, in imbalanced models, which showed that for the RUMC-based models, it spans from 52.5% (RUMC-based logistic regression) to 57.2% (RUMC-based k-nearest neighbor). Organizations and decision-makers could make use of RUMC and machine learning algorithms in predicting the severity of a crash occurrence, managing the present, and planning the future of their works [6].

There are many factors that cause traffic accidents. Previous research showed the most often factor contributing to the accident occurrence are human factors, with driver inattention being the highest, which could be caused by several causes as e.g.distraction, overloading attention, monotonous driving, etc.[5]. However, non-human factors have also caused accidents. One study by Jalilian et. al in 2019 [7] showed a significant relationship between fatal RTAs and factors such as; the sort of the road, the hindered visibility, the location of the accident, the accidentsâ€™ place, the climate, and lighting of the day (P<0.05). When it was cloudy, the chance was 2.60 times more than when was clear (P<0.05). But the sample size used was small, with only 2314 accidents dataset examined.

---

## 5. DATA COLLECTION

The dataset comes from the Waka Kotahi Crash Analysis System (CAS), which records all traffic crashes reported to data.gov.nz by the NZ Police. CAS covers crashes on all New Zealand roadways or places where the public have legal access with a motor vehicle.  

The Dataset URL is as follows: 

1. [Dataset Website](https://catalogue.data.govt.nz/dataset/crash-analysis-system-cas-data5)  
2. [Actual Dataset URL](https://opendata-nzta.opendata.arcgis.com/datasets/NZTA::crash-analysis-system-cas-data-1.csv?where=1=1&outSR=%7B%22latestWkid%22%3A2193%2C%22wkid%22%3A2193%7D)  

The dataset was downloaded from data.gov.nz on 30 Oct 2023. As of 30 Oct 2023, data was available from economic year 1999/2000 to 2022/2023, and has 821,744 observations.


---

## 6. DATA CLEANING (Mithi/Yao Hong)

```{r}
# Load the required libraries
library(dplyr)
library(ggplot2)
library('reshape2')

# retrieve large dataset
d1 <- read.csv("Crash_Analysis_System_(CAS)_data.csv")
str(d1)
summary(d1)
```


```{r}
# Subset data to smaller subset by the following categories:
# Year = Crash Year
# Vehicle Types = bicycle, bus, carStationWagon, moped, motorcycle, schoolBus, suv, taxi, truck, vanOrUtility
# Crash Location = crashLocation1, crashLocation2, region
# Severity of crash = crashSeverity, fatalCount, minorInjuryCount, seriousInjuryCount
# Accident location conditions = light, flatHill, roadLane, roadSurface, WeatherA
# Others = Holiday, areaUnitID

data <- select(d1, crashYear,  
                   bicycle, bus, carStationWagon, moped, motorcycle, schoolBus, suv, taxi, truck, vanOrUtility, 
                   crashLocation1, crashLocation2, region, 
                   crashSeverity, fatalCount, minorInjuryCount, seriousInjuryCount, 
                   light, flatHill, roadLane, roadSurface, weatherA, 
                   holiday, areaUnitID)

# Structure of dataset
str(data)
summary(data)
```

Find NAs and whether there are any outliers. Number of NA values are very small and will be deleted. Box plot shows no outliers.

```{r}
# Remove NAs
data <- na.omit(data)

# Finding outliers for vehicle type accidents
boxplot(data$bicycle, data$bus, data$carStationWagon, data$moped, data$motorcycle, data$schoolBus, data$suv,
        data$taxi, data$truck, data$vanOrUtility,
        names=c("Bicycle", "Bus", "Car", "Moped", "Motorcycle", "SchoolBus", "Suv", "Taxi", "Truck", "Van"))

# Finding outliers for injury types
boxplot(data$fatalCount, data$minorInjuryCount, data$seriousInjuryCount,
        names=c("Fatality", "MinorInjury", "SeriousInjury"))

# Replacing empty regions values with "Unknown" label
data <- data %>% mutate(region = ifelse(region == "", 'Unknown', region))
data <- data %>% mutate(flatHill = ifelse(flatHill == "Null", 'Unknown', flatHill))
data <- data %>% mutate(roadLane = ifelse(roadLane == "Null", 'Unknown', roadLane))
data <- data %>% mutate(roadSurface = ifelse(roadSurface == "Null", 'Unknown', roadSurface))
data <- data %>% mutate(weatherA = ifelse(weatherA == "Null", 'Unknown', weatherA))

# Creating a column for total_vehicles involved in accidents - sum of bicycle, bus etc.
data <- data %>% mutate(total_vehicles = rowSums(.[2:11]))

# Showcase number of accidents per year
barplot(table(data$crashYear),
        main="Number of accidents per year from 2000 - 2023",
        col = "red",
        xlab = "Year",
        ylab = "Number of accidents")
```


---

## 7. EXPLORATORY DATA ANALYSIS  (Mithi/Yao Hong)
```{r}

# Reduce dataset to last 8 years of data (2015 to 2022)
data <- filter(data, crashYear >= 2015 & crashYear < 2023)

# Overview of data
str(data)

# Summary of data
summary(data)

# Missing value checks
cat("Total number of missing values:", sum(is.na(data)), "\n")

# Saving data into RDS for reusability
saveRDS(data, file = "data.rds")
```

```{r}
# Showing number of accidents per year from reduced dataset (for last 8 years)
barplot(table(data$crashYear),
        main="Number of accidents per year from 2015 - 2022",
        ylim = c(0,50000),
        col = "red",
        xlab = "Year",
        ylab = "Number of accidents")
```

```{r}
# Showing number vehicle type crashes by year
data_vehicles <- select(data, crashYear, bicycle, bus, carStationWagon, moped, motorcycle, schoolBus,
                        suv, taxi, truck, vanOrUtility)
vehicles_melted <- melt(data_vehicles, id.vars="crashYear")
vehicles_melted <- vehicles_melted %>% group_by(crashYear, variable) %>% 
  summarise(total_accident=sum(value))
```
```{r}
ggplot(vehicles_melted, aes(x = crashYear, y = total_accident, color = variable)) +
  geom_line(linetype =1,
            lwd = 1.1) + 
  ggtitle("Number of crashes by vehicle year (2015 - 2022)") + xlab("Year") + ylab("Total crashes")
```

```{r}
# Plotting graphs to show contribution of road factors to accidents

f1 <- ggplot(data, aes(x = light, fill = crashSeverity)) + geom_bar(position = "stack") + theme(axis.text.x = element_text(angle = 90, size = 10)) + 
  ggtitle("Number of Accidents by Road Lighting") +xlab("Road Lighting") + ylab("Total crashes")
f1

f2 <- ggplot(data, aes(x = flatHill, fill = crashSeverity)) + geom_bar(position = "stack") + theme(axis.text.x = element_text(angle = 90, size = 10)) + 
  ggtitle("Number of Accidents by Road Inclination") + xlab("Flat / Hill Road") + ylab("Total crashes")
f2

f3 <- ggplot(data, aes(x = roadLane, fill = crashSeverity)) + geom_bar(position = "stack") + theme(axis.text.x = element_text(angle = 90, size = 10)) + 
  ggtitle("Number of Accidents by Number of Road Lanes") +xlab("Road Lanes") + ylab("Total crashes")
f3

f4 <- ggplot(data, aes(x = roadSurface, fill = crashSeverity)) + geom_bar(position = "stack") + theme(axis.text.x = element_text(angle = 90, size = 10)) +
  ggtitle("Number of Accidents by Road Conditions") + xlab("Road Conditions") + ylab("Total crashes")
f4

f5 <- ggplot(data, aes(x = weatherA, fill = crashSeverity)) + geom_bar(position = "stack") + theme(axis.text.x = element_text(angle = 90, size = 10))+ 
  ggtitle("Number of Accidents by Weather Conditions") + xlab("Weather Conditions") + ylab("Total crashes")
f5

# Arranging graphs in a single plot
library(ggpubr)
plot <- ggarrange(f1, f2, f3, f4, f5, ncol=3, nrow=2, common.legend = TRUE, legend="bottom")
annotate_figure(plot, top = text_grob("Number of accidents by different road condition categories"))
```

```{r}
# Showing number of accidents by crash severity types
barplot(table(data$crashSeverity),
        col = "blue",
        ylim = c(0,200000),
        ylab = "Number of accidents",
        xlab = "Crash Severity",
        main = "Number of crashes by severity after accidents (2015 - 2022)")
```

```{r}
# Showing number of injury by injury types
sumdata <- select(data, fatalCount, minorInjuryCount, seriousInjuryCount)
sumdata <- colSums(sumdata)
barplot(sumdata,
        col = "green",
        ylim = c(0,90000),
        ylab = "Number of accidents",
        xlab = "Injury Severity",
        main = "Number of injuries by severity after accidents (2015 - 2022)")

```

```{r, results='hide'}
# Showing number injury types by year
data_injury <- select(data, crashYear, fatalCount, minorInjuryCount, seriousInjuryCount)
injury_melted <- melt(data_injury, id.vars="crashYear")
injury_melted <- injury_melted %>% group_by(crashYear, variable) %>% 
  summarise(total_injury=sum(value))
ggplot(injury_melted, aes(x = crashYear, y = total_injury, color = variable)) +
  geom_line(linetype =1,
            lwd = 1.1) + 
  ggtitle("Number of injury types by year (2015 - 2022)") + xlab("Year)") + ylab("Total injuries")
```

```{r}
# Shows Holiday Period with highest accidents
ggplot(data, aes(x = holiday, fill = crashSeverity)) + geom_bar(position = "stack") + theme(axis.text.x = element_text(angle = 90, size = 10)) + 
  ggtitle("Checking if accidents happened during festive holidays") + xlab("Festive Type") + ylab("Total accidents")
```

```{r}
# Shows Region with highest accidents
ggplot(data, aes(x = region, fill = crashSeverity)) + geom_bar(position = "stack") + theme(axis.text.x = element_text(angle = 90, size = 10)) + 
  ggtitle("Number of accidents by region") + xlab("Region") + ylab("Total accidents")
```

---


## 7. DATA METHODOLOGY  (Wei Ven / Ain)

### Random Forest Classification Model
This model aims to predict leves of crash severity: Fatal, Minor, Non-Injury, Serious by using conditions of road and region as its predictors.
```{r, message = FALSE, warning = FALSE}
# Load necessary libraries
library(caret)
library(ggplot2)
library(dplyr)
library(randomForest)

# Read data
crash_data <- readRDS("data.rds")

# Select relevant columns for prediction
predictors <- crash_data %>%
  select(
    light, flatHill, roadLane, roadSurface, weatherA, region,
    crashLocation1, crashLocation2, crashSeverity
  )

# Factorize crashSeverity for modeling
predictors$crashSeverity <- factor(
  predictors$crashSeverity,
  levels = c("Fatal Crash", "Minor Crash", "Non-Injury Crash", "Serious Crash")
)

```

To determine the best training and validation datasets proportion, we have generate a learning curve where the model accuracy is evaluated at different proportions of training set.
The proportion where there is least loss between training and validation datasets accuracies is selected to run the model.

```{r, message = FALSE}

# Function to generate learning curves
generate_learningCurve <- function(data) {
  # Initialize vectors to store training and validation set sizes and their respective accuracies
  train_sizes <- seq(0.1, 0.9, by = 0.1)
  accuracy_results <- data.frame(
    Training_Size = numeric(length(train_sizes)),
    Training_Accuracy = numeric(length(train_sizes)),
    Validation_Accuracy = numeric(length(train_sizes)),
    stringsAsFactors = FALSE
  )
  
  for (i in seq_along(train_sizes)) {
    set.seed(123)  # Set seed for reproducibility
    trainIndex <- createDataPartition(
      data$crashSeverity,
      p = train_sizes[i],
      list = FALSE,
      times = 1
    )
    data_train <- data[trainIndex, ]
    data_val <- data[-trainIndex, ]

    # Train the model
    format <- crashSeverity ~ . - crashSeverity
    model <- randomForest(format, data = data_train, ntree = 200)

    # Make predictions on both training and validation sets
    train_predictions <- predict(model, newdata = data_train)
    val_predictions <- predict(model, newdata = data_val)

    # Calculate accuracy for both sets
    accuracy_results[i, "Training_Size"] <- train_sizes[i] * 100
    accuracy_results[i, "Training_Accuracy"] <- confusionMatrix(train_predictions, data_train$crashSeverity)$overall['Accuracy']
    accuracy_results[i, "Validation_Accuracy"] <- confusionMatrix(val_predictions, data_val$crashSeverity)$overall['Accuracy']

  }


  # Find the best training size based on validation accuracy
  best_size <- accuracy_results[which.min(abs(accuracy_results$Training_Accuracy - accuracy_results$Validation_Accuracy)), "Training_Size"]

  # Plot learning curves
  learning_curve_plot <- ggplot(accuracy_results, aes(x = Training_Size)) +
    geom_line(aes(y = Training_Accuracy, color = "Training Accuracy")) +
    geom_line(aes(y = Validation_Accuracy, color = "Validation Accuracy")) +
    labs(x = "Training Set Size (%)", y = "Accuracy", color = "Curve") +
    ggtitle("Learning Curves") +
    theme_minimal() +
    geom_vline(xintercept = best_size, linetype = "dashed", color = "red") +
    annotate("text", x = best_size, y = max(accuracy_results$Validation_Accuracy),
             label = paste("Best Size:", best_size), color = "red", vjust = -0.5)
  
  list(best_size = best_size, learning_curve_plot = learning_curve_plot)
}

```



```{r, message = FALSE}
# Call the function with crash_data
learning_curve_info <- generate_learningCurve(predictors)
# learning_curve_info
```

Finally, with the determined size, the severity of crash is predicted through random forest model with training data.
The model's performance is evaluated by using a confusion matrix.
```{r}

set.seed(123)
trainIndex <- createDataPartition(predictors$crashSeverity, p = (learning_curve_info$best_size / 100),
                                  list = FALSE, times = 1)
data_train <- predictors[trainIndex, ]
data_test <- predictors[-trainIndex, ]

# Training the Random Forest model
format <- crashSeverity ~ . - crashSeverity
model_rf <- randomForest(format, data = data_train, ntree = 200)

# Predicting crashSeverity
predictions <- predict(model_rf, newdata = data_test)

# Model evaluation
conf_matrix <- confusionMatrix(predictions, data_test$crashSeverity)

# Output confusion matrix
conf_matrix

```



---

## 8. DATA INTERPRETATION  (Wei Ven / Ain)

### Evaluating Random Forest Model

#### Interpreting learning curve
- Plotting the learning curve helps in evaluating whether data is a good fit. 
- The graph indicates that the validation datasets are reaching stability, but continues to have a persistent gap between training and validation accuracy.
- This may suggest a possible underfitting where the model has not fully capture the complexities in the data, or feature relevance issues, where the feature of road conditions might be insufficient or irrelevant in predicting crash severity.

```{r, echo = FALSE}
# Call the function with crash_data
learning_curve_info$learning_curve_plot
```

#### Confusion Matrix:

- **Accuracy:** Overall accuracy of the model is 69.33%.
- **Class-Specific Metrics:**
  - Fatal Crash: 
    - Low sensitivity (0%) but high specificity (100%) in identifying True Negatives.
    - The model entirely misses predicting fatal crashes
  - Minor Crash: 
    - High specificity (99.70%) but low sensitivity (1.78%).
    - The model struggles to identify minor crashes accurately.
  - Non-Injury Crash: 
    - Low specificity (2.08%) and very high sensitivity (99.97%).
    - The model heavily biases towards predicting non-injury crashes, missing out on other types.
  - Serious Crash: 
    - Both specificity and sensitivity are relatively low.
    - Similar to fatal crashes, the model entirely misses predicting serious crashes.


#### Overall Assessment:
- **Accuracy and Kappa:** The accuracy of 69.33% is above the No Information Rate of 68.92%, suggesting some predictive power. However, the Kappa statistic of 0.0226 indicates poor agreement between predicted and observed outcomes.
- **Class-Specific Assessment:**
  - The model performs well in predicting Non-Injury Crashes but struggles with Minor and Serious Crashes.
  - For Minor Crashes, while the specificity is high, sensitivity is notably low.
  - Serious Crashes are particularly challenging for the model, indicated by low sensitivity and specificity.

#### Model Interpretation

- The model exhibits poor performance in predicting "Fatal Crash," "Minor Crash," and "Serious Crash," as indicated by low sensitivity values for these classes.
- High specificity is observed for most classes, suggesting good identification of non-occurrences of certain crash types.
- The Positive Predictive Value is reasonably good for "Non-Injury Crash" but is NaN for "Fatal Crash," implying the model failed to make any true positive predictions for this class.
- Overall, the model demonstrates moderate accuracy but struggles in correctly predicting certain critical classes like "Fatal Crash" and "Serious Crash." 
- This could be due to data imbalance between levels of crash severity, which causes the model to struggle in predicting Non-Injury and Fatal crashes.
- Further model tuning or feature engineering may be necessary to enhance predictions for these classes.





---

## 9. RECOMMENDATIONS AND FUTURE  (Mithi)
  

---

## 10. CONCLUSION  (Mithi)
  

---

## 11. OPTIONAL - DATA PRODUCT (All)


---

## 12. REFERENCES  (All)

1. WHO|10 Facts on Global Road Safety. Accessed: Oct. 10, 2018. [Online].Available: http://www.who.int/features/factfiles/roadsafety/en/
2. Santos, D., Salas, J., Quaresma, P. Machine Learning Approaches to Traffic Analysis and Hotspot Prediction. *Computers* 2021, 10(12), 157; [https://doi.org/10.3390/computers10120157](https://doi.org/10.3390/computers10120157)
3. Mai, J., Ding, Y., Cheng, J. C. P., Tan, Y., Gan, V. J. L.,Zhang, J.C. Analyzing the Leading Causes of Traffic Fatalities
Using XGBoost and Grid-Based Analysis: A City Management Perspective. *IEEE Access* 2019, Vol 7. [10.1109/ACCESS.2019.2946401](10.1109/ACCESS.2019.2946401)
4. HÃ©bert, A.; GuÃ©don, T.; Glatard, T.; Jaumard, B. High-Resolution Road Vehicle Collision Prediction for the City of Montreal. *Proceedings of the 2019 IEEE International Conference on Big Data (Big Data), Los Angeles*, CA, USA, 9â€“12 December 2019.
5. BucsuhÃ¡zya, K., MatuchovÃ¡a, E., ZÅ¯valaa, R., MoravcovÃ¡a, P., KostÃ­kovÃ¡a, M., Mikuleca, R. Human factors contributing to the road traffic accident occurrence. AIIT 2nd International Congress on Transport Infrastructure and Systems in a changing world
(TIS ROMA 2019), 23rd-24th September 2019, Rome, Italy.
6. Fiorentini, N., Losa, M. Handling Imbalanced Data in Road Crash Severity Prediction by Machine Learning Algorithms. *Infrastructures* 2020, 5(7), 61; [https://doi.org/10.3390/infrastructures507006](https://doi.org/10.3390/infrastructures507006)
7. Jalilian, M.M, Safarpour, H., Bazyar, J., Keykaleh, M.S., Malekyan, L., Khorshidi, A. Environmental Related Risk Factors to Road Traffic Accidents in Ilam, Iran. *Med Arch.* 2019 Jun; 73(3): 169â€“172.



